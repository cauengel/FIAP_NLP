{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24730.960917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14277.792868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12366.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37095.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49460.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count  49459.000000\n",
       "mean   24730.960917\n",
       "std    14277.792868\n",
       "min        1.000000\n",
       "25%    12366.500000\n",
       "50%    24731.000000\n",
       "75%    37095.500000\n",
       "max    49460.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#https://s3.amazonaws.com/aulas-fiap/imdb-reviews-pt-br.csv\n",
    "df_original = pd.read_csv('https://s3.amazonaws.com/aulas-fiap/imdb-reviews-pt-br.csv')\n",
    "\n",
    "df_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_original.sample(5000,random_state=71)\n",
    "df = df_original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converte todas as palavras para minúsculo \n",
    "df.text_pt = df.text_pt.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "#Vetoriza o texto utilizando TFID em unigramas\n",
    "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
    "vect.fit(df.text_pt)\n",
    "text_vect = vect.transform(df.text_pt)\n",
    "\n",
    "#Treina com a proporção de 80% para treinamento e 20% para teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    text_vect, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076632006864927\n"
     ]
    }
   ],
   "source": [
    "#Testa com Árvore de Decisão \n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = tree.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "print(tree.get_params())\n",
    "\n",
    "parametros = {'criterion': ['gini','entropy'],\n",
    "              'splitter': ['random','best'],\n",
    "              'max_depth': [3,5,9,11],\n",
    "              'min_samples_split': [2,4,6,8] }\n",
    "        \n",
    "tree_opt = GridSearchCV(tree, parametros, scoring='f1_weighted')\n",
    "\n",
    "tree_opt.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = tree_opt.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "print(f1)\n",
    "print(tree_opt.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = neigh.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "print(neigh.get_params())\n",
    "\n",
    "parametros = {'n_neighbors': [3,5,7],\n",
    "              'weights': ['uniform','distance'],\n",
    "              'algorithm': ['ball_tree','kd_tree','brute'],\n",
    "               'p' : [1,2]}\n",
    "        \n",
    "neigh_opt = GridSearchCV(neigh, parametros, scoring='f1_weighted')\n",
    "\n",
    "neigh_opt.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = neigh_opt.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "print(f1)\n",
    "print(neigh_opt.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8737282798268138\n"
     ]
    }
   ],
   "source": [
    "#Testa com SVM \n",
    "\n",
    "## Bom F1 Score \n",
    "#### F1 Score de 87,37%\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(C=100, kernel='linear',random_state =42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = svm_clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888906477176183\n"
     ]
    }
   ],
   "source": [
    "#Testa com SVM Linear\n",
    "#### MELHOR COM 88,88% ####\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "svm_linear = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = svm_linear.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "print(svm_clf.get_params())\n",
    "\n",
    "#parametros = {'kernel': ['linear', 'poly', 'rbf'],\n",
    "#              'C': [1.0,2.0,100.0],\n",
    "#              'degree': [2,3,4,5],\n",
    "#              'gamma': ['auto','scale'],\n",
    "#              'coef0' : [0.0,1.0,4.0],\n",
    "#              'decision_function_shape' :['ovo','ovr'],\n",
    "#              'shrinking' : [True,False]}\n",
    "\n",
    "parametros = {'kernel': ['linear', 'poly', 'rbf'],\n",
    "              'C': [90.0,100.0,120.0],\n",
    "              'degree': [3,4],\n",
    "              'decision_function_shape' :['ovo','ovr'] }\n",
    "\n",
    "\n",
    "svm_opt = GridSearchCV(svm_clf, parametros, scoring='f1_weighted')\n",
    "\n",
    "svm_opt.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = svm_opt.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "print(f1)\n",
    "print(svm_opt.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157078480589882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#rand_forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=200,random_state=42,max_depth=10)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = rand_forest.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "print(rand_forest.get_params())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parametros = {\n",
    "              'max_depth': [40, None],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'n_estimators': [200, 400, 1000]}\n",
    "\n",
    "\n",
    "rand_forest_opt = GridSearchCV(rand_forest, parametros, scoring='f1_weighted')\n",
    "\n",
    "rand_forest_opt.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = rand_forest_opt.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "print(f1)\n",
    "print(rand_forest_opt.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8570078748299506\n"
     ]
    }
   ],
   "source": [
    "#### Bom modelo também ####\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_berno = BernoulliNB()\n",
    "\n",
    "naive_berno.fit(X_train,y_train)\n",
    "\n",
    "y_prediction = naive_berno.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8616663092276419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_multi = MultinomialNB()\n",
    "\n",
    "naive_multi.fit(X_train,y_train)\n",
    "\n",
    "y_prediction = naive_multi.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def xgb_f1(y,t):\n",
    "    t = t.get_label()\n",
    "    y_bin = [1. if y_cont > 0.5 else 0. for y_cont in y] # binaryzing your output\n",
    "    return 'f1',f1_score(t,y_bin)\n",
    "\n",
    "clf = xgb.XGBClassifier(max_depth=15, learning_rate=0.004,\n",
    "                            n_estimators=200,\n",
    "                            booster='gbtree',\n",
    "                            silent=True,   objective='binary:logistic',\n",
    "                            nthread=-1, gamma=0,\n",
    "                            min_child_weight=1, max_delta_step=0, subsample=0.8,\n",
    "                            colsample_bytree=0.6,\n",
    "                            base_score=0.5,\n",
    "                            seed=0, missing=None)\n",
    "\n",
    "\n",
    "#clf.fit(X_train, y_train, eval_metric=xgb_f1,\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#         early_stopping_rounds=900)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train, eval_metric=xgb_f1,\n",
    "         eval_set=[(X_train, y_train)],\n",
    "         early_stopping_rounds=900)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_pred, y_test, average='weighted')\n",
    "\n",
    "\n",
    "print(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Tirando stop words utilizando o spacy \n",
    "# Gerando novamente os vetores de teste  \n",
    "pt = spacy.load('pt_core_news_sm')\n",
    "\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "\n",
    "\n",
    "stop_words_spacy = nlp.Defaults.stop_words\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vect_stop = TfidfVectorizer(ngram_range=(1,1), use_idf=True,stop_words=stop_words_spacy)\n",
    "vect_stop.fit(df.text_pt)\n",
    "text_vect_stop = vect_stop.transform(df.text_pt)\n",
    "\n",
    "X_train_stop,X_test_stop,y_train_stop,y_test_stop = train_test_split(\n",
    "    text_vect_stop, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7139183382583874\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train_stop, y_train_stop)\n",
    "\n",
    "y_prediction = tree.predict(X_test_stop)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stop, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8543677396298509\n"
     ]
    }
   ],
   "source": [
    "# Teste com Regressão Linear Bernoulli \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_berno = BernoulliNB()\n",
    "\n",
    "naive_berno.fit(X_train_stop,y_train_stop)\n",
    "\n",
    "y_prediction = naive_berno.predict(X_test_stop)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stop, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8610960619816452\n"
     ]
    }
   ],
   "source": [
    "# Testa com multinomialNB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_multi = MultinomialNB()\n",
    "\n",
    "naive_multi.fit(X_train_stop,y_train_stop)\n",
    "\n",
    "y_prediction = naive_multi.predict(X_test_stop)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stop, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8816112827428741\n"
     ]
    }
   ],
   "source": [
    "#Testa com SVM Linear\n",
    "#### AINDA É MELHOR COM STOP WORDS 88,16% (SEM STOP WORDS) vs 88,88% (COM STOP WORDS) ####\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "svm_linear = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "svm_linear.fit(X_train_stop, y_train_stop)\n",
    "\n",
    "y_prediction = svm_linear.predict(X_test_stop)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stop, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "print(naive_multi.get_params())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parametros = {\n",
    "              'alpha': [1.0,2.0,4.0],\n",
    "              'fit_prior': [True, False]}\n",
    "\n",
    "\n",
    "naive_multi_opt = GridSearchCV(naive_multi, parametros, scoring='f1_weighted')\n",
    "\n",
    "naive_multi_opt.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = naive_multi_opt.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "print(f1)\n",
    "print(naive_multi_opt.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         \n",
    "#X_kfold = text_vect.todense()\n",
    "#Y_kfold = df.sentiment.as_matrix()\n",
    "\n",
    "\n",
    "X_kfold = X_train.todense()\n",
    "Y_kfold = y_train.as_matrix()\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "#kf = StratifiedKFold(Y_kfold, k = 10, indices=True)\n",
    "kf = StratifiedKFold(n_splits=10,random_state=42,shuffle=True)\n",
    "\n",
    "#kf = StratifiedShuffleSplit(n_splits=10,random_state=42)\n",
    "\n",
    "clf = naive_multi_opt\n",
    "\n",
    "\n",
    "best_model = None \n",
    "best_f1 = -1 \n",
    "\n",
    "for train_index, test_index in kf.split(X_kfold,Y_kfold):  \n",
    "    X_train_kfold, X_test_kfold = X_kfold[train_index], X_kfold[test_index]\n",
    "    y_train_kfold, y_test_kfold = Y_kfold[train_index], Y_kfold[test_index]\n",
    "    \n",
    "    print(X_train_kfold.shape[0])\n",
    "    print(y_train_kfold.shape[0])\n",
    "    clf.fit(X_train_kfold, y_train_kfold)\n",
    "    y_prediction = clf.predict(X_test_kfold)\n",
    "    f1 = f1_score(y_prediction, y_test_kfold, average='weighted')\n",
    "        \n",
    "    print(f1)\n",
    "\n",
    "\n",
    "    X_final_test = X_test.todense()\n",
    "Y_final_test = y_test.as_matrix()\n",
    "\n",
    "y_pred = best_model.predict(X_final_test)\n",
    "\n",
    "f1 = f1_score(y_pred,Y_final_test,average='weighted')\n",
    "    \n",
    "print(f1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 900\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df.text_pt.values)\n",
    "X = tokenizer.texts_to_sequences(df.text_pt.values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "                 \n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "                 \n",
    "                 \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = [f1])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df.sentiment).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 8, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,score_f1 = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"f1_score: %.4f\" % (score_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
